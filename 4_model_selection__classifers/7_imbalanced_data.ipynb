{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imbalanced-Balance\" data-toc-modified-id=\"Imbalanced-Balance-1\">Imbalanced Balance</a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-2\">Learning Outcomes</a></span></li><li><span><a href=\"#-What-is-Imbalanced-Data?\" data-toc-modified-id=\"-What-is-Imbalanced-Data?-3\"> What is Imbalanced Data?</a></span></li><li><span><a href=\"#All-real-world-data-is-dirty.\" data-toc-modified-id=\"All-real-world-data-is-dirty.-4\">All real-world data is dirty.</a></span></li><li><span><a href=\"#Most-real-world-data-is-imbalanced.\" data-toc-modified-id=\"Most-real-world-data-is-imbalanced.-5\">Most real-world data is imbalanced.</a></span></li><li><span><a href=\"#What-are-techniques-that-can-help-with-class-imbalances?\" data-toc-modified-id=\"What-are-techniques-that-can-help-with-class-imbalances?-6\">What are techniques that can help with class imbalances?</a></span></li><li><span><a href=\"#1)-Ignore-it.-\" data-toc-modified-id=\"1)-Ignore-it.--7\">1) Ignore it. </a></span></li><li><span><a href=\"#2)-Go-get-more-data-from-the-smaller-classes.\" data-toc-modified-id=\"2)-Go-get-more-data-from-the-smaller-classes.-8\">2) Go get more data from the smaller classes.</a></span></li><li><span><a href=\"#3)-Resample\" data-toc-modified-id=\"3)-Resample-9\">3) Resample</a></span></li><li><span><a href=\"#SMOTE-(Synthetic-Minority-Over-sampling-Technique)\" data-toc-modified-id=\"SMOTE-(Synthetic-Minority-Over-sampling-Technique)-10\">SMOTE (Synthetic Minority Over-sampling Technique)</a></span></li><li><span><a href=\"#SMOTE\" data-toc-modified-id=\"SMOTE-11\">SMOTE</a></span></li><li><span><a href=\"#4)-Pick-an-appropriate-evaluation-metrics.-\" data-toc-modified-id=\"4)-Pick-an-appropriate-evaluation-metrics.--12\">4) Pick an appropriate evaluation metrics. </a></span></li><li><span><a href=\"#5)-Pick-a-robust-algorithm\" data-toc-modified-id=\"5)-Pick-a-robust-algorithm-13\">5) Pick a robust algorithm</a></span></li><li><span><a href=\"#Support-Vector-Machines-(SVM)--101\" data-toc-modified-id=\"Support-Vector-Machines-(SVM)--101-14\">Support Vector Machines (SVM)  101</a></span></li><li><span><a href=\"#What-about-non-linearly-separable-data?\" data-toc-modified-id=\"What-about-non-linearly-separable-data?-15\">What about non-linearly separable data?</a></span></li><li><span><a href=\"#Kernel-Trick\" data-toc-modified-id=\"Kernel-Trick-16\">Kernel Trick</a></span></li><li><span><a href=\"#SVMs--&amp;-Imbalanced-Data-\" data-toc-modified-id=\"SVMs--&amp;-Imbalanced-Data--17\">SVMs  &amp; Imbalanced Data </a></span></li><li><span><a href=\"#Soft-vs-Hard-Margins\" data-toc-modified-id=\"Soft-vs-Hard-Margins-18\">Soft vs Hard Margins</a></span></li><li><span><a href=\"#6)-Change-the-loss-function\" data-toc-modified-id=\"6)-Change-the-loss-function-19\">6) Change the loss function</a></span></li><li><span><a href=\"#scikit-learn's-RandomForestClassifier\" data-toc-modified-id=\"scikit-learn's-RandomForestClassifier-20\">scikit-learn's RandomForestClassifier</a></span></li><li><span><a href=\"#scikit-learn's-RandomForestClassifier\" data-toc-modified-id=\"scikit-learn's-RandomForestClassifier-21\">scikit-learn's RandomForestClassifier</a></span></li><li><span><a href=\"#Imbalanced-Data:-Regression-vs-Classification\" data-toc-modified-id=\"Imbalanced-Data:-Regression-vs-Classification-22\">Imbalanced Data: Regression vs Classification</a></span></li><li><span><a href=\"#Imbalanced-data-also-applies-to-Regression\" data-toc-modified-id=\"Imbalanced-data-also-applies-to-Regression-23\">Imbalanced data also applies to Regression</a></span></li><li><span><a href=\"#Huber-Linear-Regression\" data-toc-modified-id=\"Huber-Linear-Regression-24\">Huber Linear Regression</a></span></li><li><span><a href=\"#Bayesian-Linear-Regression\" data-toc-modified-id=\"Bayesian-Linear-Regression-25\">Bayesian Linear Regression</a></span></li><li><span><a href=\"#Bayesian-Linear-Regression\" data-toc-modified-id=\"Bayesian-Linear-Regression-26\">Bayesian Linear Regression</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-27\">Takeaways</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-28\">Bonus Material</a></span></li><li><span><a href=\"#Further-Study\" data-toc-modified-id=\"Further-Study-29\">Further Study</a></span></li><li><span><a href=\"#Should-I-upsample-minority-class-or-down-sample-majority?\" data-toc-modified-id=\"Should-I-upsample-minority-class-or-down-sample-majority?-30\">Should I upsample minority class or down sample majority?</a></span></li><li><span><a href=\"#Imbalanced-vs-unbalanced-\" data-toc-modified-id=\"Imbalanced-vs-unbalanced--31\">Imbalanced vs unbalanced </a></span></li><li><span><a href=\"#Student-Activity\" data-toc-modified-id=\"Student-Activity-32\">Student Activity</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Imbalanced Balance</h2></center>\n",
    "\n",
    "<center><img src=\"../images/imbalanced.png\" width=\"85%\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- List strategies for handling imbalanced data.\n",
    "- Explain advantages and disadvantages of each strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2> What is Imbalanced Data?</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/data2.png\" width=\"100%\"/></center>\n",
    "\n",
    "One (or more) target classes have fewer examples relative to the other classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>All real-world data is dirty.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>Most real-world data is imbalanced.</h2></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"../images/losses.png\" width=\"95%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are techniques that can help with class imbalances?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Ignore it!\n",
    "2. Go get more data.\n",
    "3. Resample.\n",
    "4. Pick an appropriate evaluation metrics.\n",
    "5. Pick an appropriate algorithm.\n",
    "6. Pick an appropriate loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1) Ignore it. \n",
    "-----\n",
    "\n",
    "It might not matter (seriously). \n",
    "\n",
    "Small-ish differences at large scale might not effect business outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2) Go get more data from the smaller classes.\n",
    "----\n",
    "\n",
    "Spend the money and time to get more data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3) Resample\n",
    "------\n",
    "\n",
    "What are the ways to sample to rebalance class membership?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Over-sample minority group.\n",
    "2. Under-sample majority group.\n",
    "3. Representative sampling of both groups.\n",
    "4. Synthetically generate samples from minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"../images/resample.jpg\" width=\"60%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://www.svds.com/learning-imbalanced-classes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>SMOTE (Synthetic Minority Over-sampling Technique)</h2></center>\n",
    "\n",
    "> Often real-world data sets are predominately composed of “normal” examples with only a small percentage of “abnormal” or “interesting” examples. \n",
    ">\n",
    "> It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[SMOTE: Synthetic Minority Over-sampling Technique paper](https://jair.org/index.php/jair/article/view/10302/24590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>SMOTE</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/SMOTE_R_visualisation_1.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center><img src=\"../images/SMOTE_R_visualisation_2.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center><img src=\"../images/SMOTE_R_visualisation_3.png\" width=\"75%\"/></center>\n",
    "\n",
    "Synthesizes new minority instances between existing (real) minority instances\n",
    "\n",
    "Creates synthetic (not duplicate) samples of the minority class. \n",
    "\n",
    "Selecting similar records and altering that record one column at a time by a random amount within the difference to the neighboring records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source:  http://rikunert.com/SMOTE_explained\n",
    "\n",
    "Learn more:\n",
    "\n",
    "- https://medium.com/@saeedAR/smote-and-near-miss-in-python-machine-learning-in-imbalanced-datasets-b7976d9a7a79\n",
    "- https://www.youtube.com/watch?v=U3X98xZ4_no&ab_channel=BhaveshBhatt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4) Pick an appropriate evaluation metrics. \n",
    "----\n",
    "\n",
    "Avoid accuracy  \n",
    "\n",
    "$$ \\frac{correct}{total (correct + incorrect)} $$\n",
    "\n",
    "> Accuracy is the pie chart of evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the next session, we'll discuss classification evaluation metrics.\n",
    "\n",
    "In general, use a business specific evaluation metrics that are robust to imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more: \n",
    "- [Evaluation Measures for Models Assessment over Imbalanced Data Sets](https://eva.fing.edu.uy/pluginfile.php/69453/mod_resource/content/1/7633-10048-1-PB.pdf)\n",
    "- https://medium.com/coinmonks/practical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7\n",
    "- https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5) Pick a robust algorithm\n",
    "----\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png\" width=\"45%\"/></center>\n",
    "\n",
    "<center>For example, support vector machines (SVM) are very robust to class imbalances.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Support Vector Machines (SVM)  101</h2></center>\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png\" width=\"35%\"/></center>\n",
    "\n",
    "- SVM finds a hyperplane that maximizes the margin, the margin is the closest class points.\n",
    "- SVM does this by finding \"support vectors\", the closet class points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What about non-linearly separable data?</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/kernel_trick1.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"../images/kernel_trick2.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center>\"Lift\" the data by projecting it into higher dimensional space that allows for linear separation.</center>\n",
    "\n",
    "<center>In this case, square each value.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Kernel Trick</h2></center>\n",
    "\n",
    "<center><img src=\"../images/mapping.png\" width=\"75%\"/></center>\n",
    "\n",
    "Allows linear classifiers to learn non-linear boundaries by implicitly mapping into a higher-dimensional feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>SVMs  & Imbalanced Data </h2></center>\n",
    "\n",
    "<center><img src=\"../images/svm_2.png\" width=\"50%\"/></center>\n",
    "\n",
    "<center>SVM needs very few \"support vectors\", thus minimizing the impact of imbalanced data.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Soft vs Hard Margins</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/soft v hard.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "SVM are very popular to ask in interviews. \n",
    "\n",
    "SVM are popular from the education in 1990s (people educated in the 90s are in the position to hire people).\n",
    "\n",
    "SVM have elegant math. However, SVM don't perform as well in practice as other techniques (e.g., Deep Learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6) Change the loss function\n",
    "----\n",
    "\n",
    "Remember - a loss is a __weighted__ mistake.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, weight mistakes for smaller classes more highly than mistakes for larger classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>scikit-learn's RandomForestClassifier</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest™ takes weighted classes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>scikit-learn's RandomForestClassifier</h2></center>\n",
    "\n",
    "`class_weight=balanced` - classes are automatically weighted inversely proportional to how frequently they appear in the data. \n",
    "\n",
    "$w_j = \\frac{n}{kn_{j}}$\n",
    "\n",
    "$w_j$ is the weight to class $j$  \n",
    "$n$ is the number of observations  \n",
    "$j$ is the number of observations in class   \n",
    "$k$ is the total number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Imbalanced Data: Regression vs Classification</h2></center>\n",
    "\n",
    "We are primarily concerned with imbalances in classification targets.\n",
    "\n",
    "There can also be imbalances in regression targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Imbalanced data also applies to Regression</h2></center>\n",
    "\n",
    "In Regression, we want to predict a continuous numeric value. It is best if all possible target values are equally represented.\n",
    "\n",
    "You can:\n",
    "\n",
    "- Filter data without enough samples (aka, ignore).\n",
    "- Resample data.\n",
    "- Transform data to be distributed how you want. See Target Engineering section for an algorithm to address that problem.\n",
    "- Fit more robust algorithms (e.g., Huber or Bayesian Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Huber Linear Regression</h2></center>\n",
    "<center><img src=\"../images/1280px-Huber_loss.svg.png\" width=\"55%\"/></center>\n",
    "Blue line is squared error loss. Green line is Huber loss. \n",
    "\n",
    "It appears lower penalty for outliers.\n",
    "\n",
    "The slope of the Huber penalty (green) is a hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Bayesian Linear Regression</h2></center>\n",
    "\n",
    "<center><img src=\"../images/L7rS3.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Bayesian Linear Regression</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/br.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Imbalanced data is very common in real-world data science.\n",
    "- Strategies to handle it:\n",
    "    1. Ignore it!\n",
    "    2. Go get more data.\n",
    "    3. Resample.\n",
    "    4. Pick an appropriate evaluation metrics, algorithm, and loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Further Study\n",
    "------\n",
    "\n",
    "- Tomek Links\n",
    "- NearMiss-1 & NearMiss-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Should I upsample minority class or down sample majority?</h2></center>\n",
    "\n",
    "It depends…\n",
    "\n",
    "- On the domain. Does one class mater more than another?\n",
    "- Data distribution. Is the minority class distributed in a degenerate way that SMOTE does not make sense?\n",
    "- On absolute size of the data. If you have data to spare, then downsample. Most of the time, there is not enough data so upsampling is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://stats.stackexchange.com/questions/152823/how-to-balance-my-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced vs unbalanced \n",
    "------\n",
    "\n",
    "Imbalanced:\n",
    "\n",
    "- Lack of balance\n",
    "- The state of being out of equilibrium or out of proportion\n",
    "\n",
    "Unbalanced\n",
    "\n",
    "- Not balanced\n",
    "- Not in equilibrium\n",
    "- Mentally disordered or deranged\n",
    "- Not adjusted so as to make credits equal to debits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Student Activity</h2></center>\n",
    "\n",
    "With your colleagues, write a loss function for imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
