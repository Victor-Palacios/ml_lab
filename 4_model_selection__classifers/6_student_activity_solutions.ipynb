{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Categorical-features-in-tree-based-algorithms-in-scikit-learn\" data-toc-modified-id=\"Categorical-features-in-tree-based-algorithms-in-scikit-learn-1\">Categorical features in tree-based algorithms in scikit-learn</a></span></li><li><span><a href=\"#Setting-up-and-applying-cross-validation-search\" data-toc-modified-id=\"Setting-up-and-applying-cross-validation-search-2\">Setting up and applying cross validation search</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Categorical features in tree-based algorithms in scikit-learn</h2></center>\n",
    "\n",
    "Below is broken code. The categorical data is not working with a tree-based algorithm. Your task is to get the categorical data to work with tree-based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.pipeline      import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['target'] = ['pos','neg', 'pos',  'neg']\n",
    "data['pet']    = ['üê±',  'üê±',  'üê±',  'üê∂']  # Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix the broken code so the data can modeled with tree-based algorithm\n",
    "\n",
    "# pipe = Pipeline([('tree_algorithm', RandomForestClassifier())])\n",
    "\n",
    "# pipe.fit(X=data[['pet']], \n",
    "#          y=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cat_encoder', OneHotEncoder()),\n",
       "                ('tree_algorithm', RandomForestClassifier())])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A solution\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "                  ('cat_encoder',    OneHotEncoder()),        # Explicitly encode categorical features\n",
    "                  ('tree_algorithm', RandomForestClassifier())\n",
    "                ])\n",
    "\n",
    "pipe.fit(X=data[['pet']], \n",
    "         y=data['target'])\n",
    "\n",
    "\n",
    "# Tree-based algorithms in scikit-learn do NOT automatically handle categorical features.\n",
    "# Categorical features must be explicitly encoded. A common encoding scheme is One Hot Encoding.\n",
    "\n",
    "# Sources of Inspiration\n",
    "# This issue has been outstanding for many years. Do not wait for it be resolved! - https://github.com/scikit-learn/scikit-learn/pull/12866\n",
    "# https://stackoverflow.com/questions/38108832/passing-categorical-data-to-sklearn-decision-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Setting up and applying cross validation search</h2></center>\n",
    "\n",
    "I have started defining the search space. Your task is to define the rest of the search space and run `RandomizedSearchCV` to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # üëà Hint to programmatically create search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have started to define the search space. \n",
    "# Your task is to define the search space for other important hyperparameters.\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = 2 ** np.arange(5)\n",
    "\n",
    "serach_space = {'max_features': max_features,\n",
    "                'bootstrap': bootstrap,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Programmatically define the following hyperparameter space values and add them to the search space\n",
    "# Pick reasonable number of values and appropriate sampling within the range\n",
    "\n",
    "# n_estimators - should be from 1 to 100\n",
    "# max_depth - should be from 10 to 110, also include None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "assert 'n_estimators' in serach_space\n",
    "assert 'max_depth'    in serach_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': ['auto', 'sqrt'],\n",
       " 'bootstrap': [True, False],\n",
       " 'min_samples_split': [2, 5, 10, 20],\n",
       " 'min_samples_leaf': array([ 1,  2,  4,  8, 16]),\n",
       " 'n_estimators': [1, 8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 100],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A solution\n",
    "\n",
    "# Number of trees in random forest\n",
    "# Some hyperparameter values must be integers, not numpy.float64\n",
    "n_estimators = [int(x) for x in np.linspace(start=1, stop=100, num = 15)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start=10, stop=110, num=11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "serach_space['n_estimators'] = n_estimators\n",
    "serach_space['max_depth']    = max_depth\n",
    "serach_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble         import RandomForestClassifier\n",
    "from sklearn.model_selection  import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Define RandomizedSearchCV\n",
    "# 2. Fit RandomizedSearchCV\n",
    "# 3. Print best hyperparamters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 43,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A solution\n",
    "clf_rand_cv = RandomizedSearchCV( estimator=RandomForestClassifier(), \n",
    "                                  param_distributions=serach_space, \n",
    "                                  n_iter=25,\n",
    "                                  cv=5, \n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=False,\n",
    "                                )\n",
    "clf_rand_cv.fit(X, y)\n",
    "clf_rand_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
