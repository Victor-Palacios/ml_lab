{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Categorical-features-in-tree-based-algorithms-in-scikit-learn\" data-toc-modified-id=\"Categorical-features-in-tree-based-algorithms-in-scikit-learn-1\">Categorical features in tree-based algorithms in scikit-learn</a></span></li><li><span><a href=\"#Setting-up-and-applying-cross-validation-search\" data-toc-modified-id=\"Setting-up-and-applying-cross-validation-search-2\">Setting up and applying cross validation search</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Categorical features in tree-based algorithms in scikit-learn</h2></center>\n",
    "\n",
    "Below is broken code. The categorical data is not working with a tree-based algorithm. Your task is to get the categorical data to work with tree-based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.pipeline      import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['target'] = ['pos','neg', 'pos',  'neg']\n",
    "data['pet']    = ['üê±',  'üê±',  'üê±',  'üê∂']  # Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix the broken code so the data can modeled with tree-based algorithm\n",
    "\n",
    "# pipe = Pipeline([('tree_algorithm', RandomForestClassifier())])\n",
    "\n",
    "# pipe.fit(X=data[['pet']], \n",
    "#          y=data['target'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Setting up and applying cross validation search</h2></center>\n",
    "\n",
    "I have started defining the search space. Your task is to define the rest of the search space and run `RandomizedSearchCV` to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # üëà Hint to programmatically create search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have started to define the search space. \n",
    "# Your task is to define the search space for other important hyperparameters.\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = 2 ** np.arange(5)\n",
    "\n",
    "serach_space = {'max_features': max_features,\n",
    "                'bootstrap': bootstrap,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Programmatically define the following hyperparameter space values and add them to the search space\n",
    "# Pick reasonable number of values and appropriate sampling within the range\n",
    "\n",
    "# n_estimators - should be from 1 to 100\n",
    "# max_depth - should be from 10 to 110, also include None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "assert 'n_estimators' in serach_space\n",
    "assert 'max_depth'    in serach_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble         import RandomForestClassifier\n",
    "from sklearn.model_selection  import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Define RandomizedSearchCV\n",
    "# 2. Fit RandomizedSearchCV\n",
    "# 3. Print best hyperparamters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
