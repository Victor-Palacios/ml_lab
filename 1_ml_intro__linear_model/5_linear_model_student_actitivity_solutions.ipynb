{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesbian-nutrition",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-1\">Instructions</a></span></li><li><span><a href=\"#Challenge-Prompts\" data-toc-modified-id=\"Challenge-Prompts-2\">Challenge Prompts</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-invention",
   "metadata": {},
   "source": [
    "Instructions\n",
    "------\n",
    "\n",
    "- Complete this individually. \n",
    "\n",
    "    You must be able to fit fundamental machine learning models by yourself.\n",
    "    <br>\n",
    "- Type every command. \n",
    "\n",
    "    You learn almost nothing by copy n' pasting code. Typing the commands will build procedural fluency and you will make small typos that will force you to debug common mistakes. Tab complete is awesome, use it!\n",
    "<br>\n",
    "- Complete the activity in Deepnote. \n",
    "\n",
    "    After completion, send the link as a private message in Zoom to Brian. Time permitting, Brian might give you a quick code review. It also signals who in the class is done.\n",
    "    <br>\n",
    "- Any random seed should be set to `42` so we can compare results amongst ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mature-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fatal-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Write import statement to load boston housing data\n",
    "# - Call the following on the data set to \n",
    "#    - help function on load\n",
    "#    - keys\n",
    "#    - DESCR\n",
    "#    - feature_names\n",
    "#    - shape\n",
    "# - Load boston housing data into correctly named variables \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "european-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_boston in module sklearn.datasets._base:\n",
      "\n",
      "load_boston(*, return_X_y=False)\n",
      "    Load and return the boston house-prices dataset (regression).\n",
      "    \n",
      "    ==============   ==============\n",
      "    Samples total               506\n",
      "    Dimensionality               13\n",
      "    Features         real, positive\n",
      "    Targets           real 5. - 50.\n",
      "    ==============   ==============\n",
      "    \n",
      "    Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : bool, default=False.\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "        See below for more information about the `data` and `target` object.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : :class:`~sklearn.utils.Bunch`\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        data : ndarray of shape (506, 13)\n",
      "            The data matrix.\n",
      "        target : ndarray of shape (506, )\n",
      "            The regression target.\n",
      "        filename : str\n",
      "            The physical location of boston csv dataset.\n",
      "    \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "        DESCR : str\n",
      "            The full description of the dataset.\n",
      "        feature_names : ndarray\n",
      "            The names of features\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "        .. versionchanged:: 0.20\n",
      "            Fixed a wrong data point at [445, 0].\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_boston\n",
      "    >>> X, y = load_boston(return_X_y=True)\n",
      "    >>> print(X.shape)\n",
      "    (506, 13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Solutions\n",
    "\n",
    "from sklearn.datasets import load_boston \n",
    "help(load_boston)\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tropical-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to keep you honest \n",
    " \n",
    "assert X.shape == (506, 13)\n",
    "assert y.shape == (506,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cubic-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Write import statement to split your data into train and validation \n",
    "# - Assign train and validation data. Use seed set to 42 so you can compare answers with classmates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mexican-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solutions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation= train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "documentary-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit a baseline model \n",
    "# - Import linear regression algorithm, MSE metric, pipeline, and standardize function\n",
    "# - Create a pipeline\n",
    "# - Train algorithm in pipeline \n",
    "# - Find performance metric on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "institutional-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 22.10\n"
     ]
    }
   ],
   "source": [
    "## Solutions\n",
    "\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "from sklearn.metrics       import mean_squared_error\n",
    "from sklearn.pipeline      import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('lr',     LinearRegression())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_validation)\n",
    "\n",
    "mse = mean_squared_error(y_validation, y_pred)\n",
    "print(f\"Mean squared error: {mse:,.2f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "solar-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find out which the following linear_model algorithms is the best:\n",
    "# - Lasso\n",
    "# - Ridge\n",
    "# - ElasticNet\n",
    "# - HuberRegressor\n",
    "# - Another one of your choice that is appropiate for the data \n",
    "\n",
    "# Make your personal prediction before running the code. Which one do you apriori think will perform best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "armed-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression  - mean squared error: 22.10\n",
      "Lasso             - mean squared error: 26.01\n",
      "Ridge             - mean squared error: 22.12\n",
      "ElasticNet        - mean squared error: 26.54\n",
      "HuberRegressor    - mean squared error: 26.23\n",
      "BayesianRidge     - mean squared error: 22.21\n"
     ]
    }
   ],
   "source": [
    "## Solutions\n",
    "\n",
    "from sklearn.linear_model  import Lasso, Ridge, ElasticNet, HuberRegressor, BayesianRidge\n",
    "\n",
    "# Programmatically fit \n",
    "algorithms = [LinearRegression(), Lasso(), Ridge(), ElasticNet(), HuberRegressor(), BayesianRidge()]\n",
    "results = dict()\n",
    "\n",
    "for algo in algorithms:\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('lm',     algo)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_validation)\n",
    "    mse = mean_squared_error(y_validation, y_pred)\n",
    "    print(f\"{algo.__class__.__name__:<17} - mean squared error: {mse:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "necessary-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finalize model \n",
    "# - Retrain best algorithm on all the data \n",
    "# - Print the parameters of the final model with associated feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "occupied-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:              22.53\n",
      "Coefficients:    Crim   -0.93\n",
      "                   Zn    1.08\n",
      "                Indus    0.14\n",
      "                 Chas    0.68\n",
      "                  Nox   -2.06\n",
      "                   Rm    2.67\n",
      "                  Age    0.02\n",
      "                  Dis   -3.10\n",
      "                  Rad    2.66\n",
      "                  Tax   -2.08\n",
      "              Ptratio   -2.06\n",
      "                    B    0.85\n",
      "                Lstat   -3.74\n",
      "              "
     ]
    }
   ],
   "source": [
    "## Solutions\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('regr',  LinearRegression())])\n",
    "pipe.fit(X, y)\n",
    "\n",
    "boston_data = load_boston() # Get data bunch to display feature names\n",
    "\n",
    "print(f\"Intercept:              {pipe['regr'].intercept_:.2f}\")\n",
    "print(f\"Coefficients:\", end=\" \")\n",
    "for feature_name, coef in zip(boston_data.feature_names, pipe['regr'].coef_):\n",
    "    print(f\"{feature_name.title():>7} {coef:>7,.2f}\", end=\"\\n              \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why was the champion algorithm the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solutions\n",
    "\n",
    "\"\"\"\n",
    "The dataset has relatively few features and each one contributes to the final performance of the model.\n",
    "Thus, there is no need to regularize to increase performance.\n",
    "\n",
    "We should proceded with a regular linear regression. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-construction",
   "metadata": {},
   "source": [
    "Challenge Prompts\n",
    "------\n",
    "\n",
    "If you have extra time, try these:\n",
    "\n",
    "- Understand the data and how `StandardScaler` changes it. Visualize the univariate distribution of features before and after applying `StandScaler`.\n",
    "- Start hand-tuning the hyperparameters for algorithms. See which hyperparameter combination yields a higher score on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-dominican",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
