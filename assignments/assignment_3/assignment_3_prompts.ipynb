{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "practical-ballot",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Assignment-#3---Takehome-Challenge\" data-toc-modified-id=\"Assignment-#3---Takehome-Challenge-1\">Assignment #3 - Takehome Challenge</a></span></li><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-2\">Instructions</a></span></li><li><span><a href=\"#Rubric\" data-toc-modified-id=\"Rubric-3\">Rubric</a></span></li><li><span><a href=\"#Hints\" data-toc-modified-id=\"Hints-4\">Hints</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-basketball",
   "metadata": {},
   "source": [
    "<center><h2>Assignment #3 - Takehome Challenge</h2></center>\n",
    "\n",
    "A common step while interviewing for a Data Science job is a take-home challenge. This assignment is take-home challenge practice. \n",
    "\n",
    "It is based a true-life take-home challenge that USF MSDS graduates received last year. Some minor changes were made to make into a classroom assignment but the spirit is unchanged. \n",
    "\n",
    "You are applying to work at HotWheels, a startup selling vehicle insurance. The startup is using paid acquisition to get new customers. Your challenge is to predict if a person clicking on an ad will convert or not.\n",
    "\n",
    "\n",
    "| Feature | Definition |  Key |\n",
    "|:-------|:------|:------|\n",
    "| age | Self-reported how long the person has been alive in years |\n",
    "| cost_of_ad | in US dollars | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| device_type | Where they saw the ad |  |\n",
    "| gender |  Self-reported |  |\n",
    "| in_initial_launch_location| Did they convert right away   | 0 = No, 1 = Yes  |\n",
    "| n_drivers | Self-reported number of drivers in household  |  |\n",
    "| n_vehicles |Self-reported number of vehicles in household      |  |\n",
    "| prior_ins_tenure | Self-reported number of years they have had insurance  |  |\n",
    "\n",
    "The targets is `outcome` - convert or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-score",
   "metadata": {},
   "source": [
    "Instructions\n",
    "--------\n",
    "\n",
    "- This is a team assignment. Teams are randomly assigned through Canvas. A single notebook will be submitted per team.\n",
    "- The only resources you can use are:\n",
    "    * Course materials\n",
    "    * scikit-learn and related package documentation\n",
    "    * Your team mates\n",
    "- You should not use or reference anything else, including, but not limited to, non-team classmates and Internet websites.\n",
    "- Complete each TODO.\n",
    "- No other imports are allowed in this notebook.\n",
    "- Do not remove anything from this notebook.\n",
    "- Do not set `random_state` or any random state. Your model should be robust to small variations.\n",
    "- __Only submit final code__. There should be no extra code or commented out code. You can do cross-validation however you want, but that code is not to appear in this notebook.\n",
    "- Prediction on unseen is the primary goal of machine learning, thus a significant number of points are based on your model's performance on hold-out data that you do not have access to.\n",
    "- See [coding guidelines](https://github.com/brianspiering/ml_lab/blob/main/resources/coding_guidelines.md), [coding review rubric](https://github.com/brianspiering/ml_lab/blob/main/resources/code_review_rubric.md), and course materials for how code will be evaluated.\n",
    "\n",
    "Rubric\n",
    "-------\n",
    "\n",
    "Total: __ / 14 points\n",
    "\n",
    "- __ / 2 points - Followed all directions as written and intended.\n",
    "- __ / 2 points - Code runs completely on first try on instructor's computer.\n",
    "- __ / 2 points - Summary is clear and complete describing both preprocessing and model.\n",
    "- __ / 1 point - Summary is grammatically correct English.\n",
    "- __ / 1 point - Meets all coding guidelines / Idiomatic scikit-learn code.\n",
    "- __ / 2 points - Passed Level 1 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 2 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 3 test set performance. These point are all or none passed on tests.\n",
    "\n",
    "\n",
    "Hints\n",
    "------\n",
    "\n",
    "- Each person should attempt it individually. Then combine individual efforts in Deepnote.\n",
    "- Perform EDA in a separate notebook. I suggest the `pandas_profiling` package\n",
    "    ```\n",
    "    from pandas_profiling import ProfileReport\n",
    "    profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "    profile.to_widgets()\n",
    "    profile.to_file(\"Pandas Profiling Report.html\")\n",
    "    ```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "color-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tracked-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Do NOT import anything else\n",
    "from   category_encoders          import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   sklearn.compose            import *\n",
    "from   sklearn.ensemble           import RandomForestClassifier, ExtraTreesClassifier, IsolationForest\n",
    "from   sklearn.experimental       import enable_iterative_imputer\n",
    "from   sklearn.impute             import *\n",
    "from   sklearn.linear_model       import LinearRegression, PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from   sklearn.metrics            import roc_auc_score # We have not covered it yet in class. The basics - AUC is from 0 to 1 and higher is better.\n",
    "from   sklearn.pipeline           import Pipeline\n",
    "from   sklearn.preprocessing      import *\n",
    "from   sklearn.tree               import DecisionTreeClassifier, ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "august-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your best model for the data\n",
    "# Friendly reminders: \n",
    "# - Use only the imports given\n",
    "# - Create a pipeline instance called `pipe`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "computational-flashing",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-155f2469011c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Expect pipe object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m\"pipe\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Expect pipe object\n",
    "assert \"pipe\" in dir()\n",
    "assert type(pipe) == Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a one sentence description of your approach (less than 30 words). Put in variable named `summary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect summary object\n",
    "assert \"summary\" in dir()\n",
    "assert type(summary) == str\n",
    "assert len(summary.split()) < 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate final model on test set\n",
    "# # This code is commented out because you do not have access to the test set\n",
    "# path = \"../\"\n",
    "# X_test = pd.read_csv(path+\"instructor/assignment_3_X_test.csv\", header=0)\n",
    "# y_test = pd.read_csv(path+\"instructor/assignment_3_y_test.csv\", header=0)\n",
    "# y_test = y_test.values.ravel()\n",
    "# y_pred = pipe.predict(X_test)\n",
    "# roc_auc_score_test = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# assert roc_auc_score_test >= 0.65\n",
    "# print(\"Passed Level 1 test set performance ðŸ™‚\")\n",
    "\n",
    "# assert roc_auc_score_test >= 0.70\n",
    "# print(\"Passed Level 2 test set performance ðŸ™‚\")\n",
    "\n",
    "# assert roc_auc_score_test >= 0.75\n",
    "# print(\"Passed Level 3 test set performance ðŸ™‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-agency",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
