{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-804f0af3fa165329",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Assignment-#5:-Multiclass-Classification\" data-toc-modified-id=\"Assignment-#5:-Multiclass-Classification-1\">Assignment #5: Multiclass Classification</a></span></li><li><span><a href=\"#Problem-Statement-&amp;-Data-Overview\" data-toc-modified-id=\"Problem-Statement-&amp;-Data-Overview-2\">Problem Statement &amp; Data Overview</a></span></li><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-3\">Instructions</a></span></li><li><span><a href=\"#Rubric\" data-toc-modified-id=\"Rubric-4\">Rubric</a></span></li><li><span><a href=\"#Hints\" data-toc-modified-id=\"Hints-5\">Hints</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4c62607385fb2bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assignment #5: Multiclass Classification\n",
    "----\n",
    "<br>\n",
    "<br>\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/data_pipeline.png\" width=\"75%\"/></center>\n",
    "\n",
    "> \"Is the pipeline literally running from your laptop?\"   \n",
    "> \"Don't be silly, my laptop disconnects far too often to host a service we rely on. It's running on my phone.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0ce37636980e046c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Problem Statement & Data Overview\n",
    "-------\n",
    "\n",
    "Which classification algorithm can learn to best predict a mulitclass targets in a tabular dataset? In particular, predict the type of glass based on physical characteristics.\n",
    "\n",
    "The classification of glass types is motivated by crime scene investigation, often broken glass is left behind after a crime. The ability to identify the type of glass can help elucidate what happened at a crime scene.\n",
    "\n",
    "The 9 features are:\n",
    "\n",
    "1. RI: refractive index\n",
    "2. The relative amount of the following 8 elements:\n",
    "    - Na: Sodium Â \n",
    "    - Mg: Magnesium\n",
    "    - Al: Aluminum\n",
    "    - Si: Silicon\n",
    "    - K: Potassium\n",
    "    - Ca: Calcium\n",
    "    - Ba: Barium\n",
    "    - Fe: Iron\n",
    "\n",
    "The targets are 6 discrete types of glass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "--------\n",
    "\n",
    "- This is a team assignment. Teams are randomly assigned through Canvas. A single notebook will be submitted per team.\n",
    "- The only resources you can use are:\n",
    "    * Course materials\n",
    "    * scikit-learn and related packages documentation\n",
    "    * Your team mates\n",
    "- You should not use or reference anything else, including, but not limited to, non-team classmates and Internet websites.\n",
    "- Complete each TODO.\n",
    "- No other imports are allowed in this notebook.\n",
    "- Do not remove anything from this notebook.\n",
    "- Do not set `random_state` or any random state. Your model should be robust to small variations.\n",
    "- Prediction on unseen is the primary goal of machine learning, thus a significant number of points are based on your model's performance on hold-out data that you do not have access to.\n",
    "- See [coding guidelines](https://github.com/brianspiering/ml_lab/blob/main/resources/coding_guidelines.md), [coding review rubric](https://github.com/brianspiering/ml_lab/blob/main/resources/code_review_rubric.md), and course materials for how code will be evaluated.\n",
    "- Given the random nature of some algorithms, your final model `pipe.fit()` will be called 5 times. The highest `pipe.predict(X_test)` will be taken.\n",
    "\n",
    "Rubric\n",
    "-------\n",
    "\n",
    "Total: __ / 14 points\n",
    "\n",
    "- __ / 2 points - Followed all directions as written and intended.\n",
    "- __ / 1 point - Code runs completely on first try on instructor's computer.\n",
    "- __ / 1 point - Clarity of cross validation search code\n",
    "- __ / 2 points - Breadth of cross validation search code\n",
    "- __ / 2 point - Meets all coding guidelines / Idiomatic scikit-learn code.\n",
    "- __ / 2 points - Passed Level 1 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 2 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 3 test set performance. These point are all or none passed on tests.\n",
    "\n",
    "\n",
    "Hints\n",
    "------\n",
    "\n",
    "- Each person should attempt it individually. Then combine individual efforts in Deepnote.\n",
    "- Perform EDA in a separate notebook. I suggest the `pandas_profiling` package\n",
    "    ```\n",
    "    from pandas_profiling import ProfileReport\n",
    "    profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "    profile.to_widgets()\n",
    "    profile.to_file(\"Pandas Profiling Report.html\")\n",
    "   ```\n",
    "- Warnings are fine. Errors are not.\n",
    "- There are relatively few rows in both training and test dataset.\n",
    "- Make sure to understand how your model will be evaluated on the test dataset. \n",
    "- Start early! Even using RandomizedSearchCV, there are a lot of possible hyperparameters to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4875d81c432b3719",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-018ad63b2ae1c351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Do NOT import anything else\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base            import BaseEstimator\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics         import f1_score # This assignment's metric\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.naive_bayes     import GaussianNB\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class (you do not have to use it)\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    \"Pass through class, methods are present but do nothing.\"\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcc73eaa76bcf25a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = \"./\"\n",
    "X = pd.read_csv(path+\"assignment_5_X_train.csv\", header=0)\n",
    "y = pd.read_csv(path+\"assignment_5_y_train.csv\", header=0)\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show evidence of automated cross validation search across algorithms and hyperparameters\n",
    "\n",
    "# For the sake of time, this code will not be run. \n",
    "# It will be visually inspected for:\n",
    "#  - Clarity\n",
    "#  - Logic\n",
    "#  - Correct use of scikit-learn idioms\n",
    "#  - Breadth of search\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define pipeline with your set of final hyperparameters for all steps.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Expect pipe object\n",
    "assert \"pipe\" in dir()\n",
    "assert type(pipe) == Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code is commented out because you do not have access to the test set\n",
    "\n",
    "# # Try final model 5 times and take highest test score. \n",
    "# # WARNING - DO NOT DO THIS OUTSIDE OF CLASS. We are looking at the test set mulitple times for educational purposes only. \n",
    "\n",
    "# # Set champion to worst possible baseline\n",
    "# f1_test_best = 0 \n",
    "\n",
    "# for run in range(5):\n",
    "#     # Traing final model on all the avaible training data\n",
    "#     pipe.fit(X, y);\n",
    "    \n",
    "#     # Evaluate final model on test set\n",
    "#     path = \"./\"\n",
    "#     X_test   = pd.read_csv(path+\"instructor/assignment_5_X_test.csv\", header=0)\n",
    "#     y_test   = pd.read_csv(path+\"instructor/assignment_5_y_test.csv\", header=0)\n",
    "#     y_test   = y_test.values.ravel()\n",
    "#     y_pred   = pipe.predict(X_test)\n",
    "#     f1_test  = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "#     # Update champion score\n",
    "#     if f1_test > f1_test_best:\n",
    "#         f1_test_best = f1_test\n",
    "    \n",
    "# print(f\"{f1_test_best:,.2f}\")\n",
    "\n",
    "# assert f1_test_best >= 0.61\n",
    "# print(\"Passed Level 1 test set performance ð\")\n",
    "\n",
    "# assert f1_test_best >= 0.66\n",
    "# print(\"Passed Level 2 test set performance ð\")\n",
    "\n",
    "# assert f1_test_best >= 0.71\n",
    "# print(\"Passed Level 3 test set performance ð\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
