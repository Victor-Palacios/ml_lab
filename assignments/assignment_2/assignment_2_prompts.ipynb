{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "practical-ballot",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Assignment-#2---Preprocessing\" data-toc-modified-id=\"Assignment-#2---Preprocessing-1\">Assignment #2 - Preprocessing</a></span></li><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-2\">Instructions</a></span></li><li><span><a href=\"#Rubric\" data-toc-modified-id=\"Rubric-3\">Rubric</a></span></li><li><span><a href=\"#Hints\" data-toc-modified-id=\"Hints-4\">Hints</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-basketball",
   "metadata": {},
   "source": [
    "<center><h2>Assignment #2 - Preprocessing</h2></center>\n",
    "\n",
    "Can we predict the duration of bike trips for [Bay Wheels](https://www.lyft.com/bikes/bay-wheels)?\n",
    "\n",
    "The data comes from https://www.lyft.com/bikes/bay-wheels/system-data. \n",
    "\n",
    "I have given a subselection of the data, both rows and columns.\n",
    "\n",
    "Features used are:\n",
    "\n",
    "- Trip ID\n",
    "- Start Station Name\n",
    "- End Station Name\n",
    "- Bike ID\n",
    "- User Type (Subscriber or Customer - \"Subscriber\" = Member or \"Customer\" = Casual)\n",
    "\n",
    "The targets is Trip Duration (in seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-score",
   "metadata": {},
   "source": [
    "Instructions\n",
    "--------\n",
    "\n",
    "- This is a team assignment. Teams are randomly assigned through Canvas. A single notebook will be submitted per team.\n",
    "- The only resources you can use are:\n",
    "    * Course materials\n",
    "    * scikit-learn and related package documentation\n",
    "    * Your team mates\n",
    "- You should not use or reference anything else, including, but not limited to, non-team classmates and Internet websites.\n",
    "- Complete each TODO.\n",
    "- No other imports are allowed in this notebook.\n",
    "- Everyone will use the same algorithm with default hyperparameters. Performance differences will be only do to feature engineering.\n",
    "- __Only submit final code__. There should be no extra code or commented out code.\n",
    "- Prediction on unseen is the primary goal of machine learning, thus a significant number of points are based on your model's performance on hold-out data that you do not have access to.\n",
    "- See [coding guidelines](https://github.com/brianspiering/ml_lab/blob/main/resources/coding_guidelines.md), [coding review rubric](https://github.com/brianspiering/ml_lab/blob/main/resources/code_review_rubric.md), and course materials for how code will be evaluated.\n",
    "\n",
    "Rubric\n",
    "-------\n",
    "\n",
    "Total: __ / 14 points\n",
    "\n",
    "- __ / 2 points - Followed all directions as written and intended.\n",
    "- __ / 2 point - Code runs completely on first try on instructor's computer.\n",
    "- __ / 1 point - Code is readable. Proprocessing code can become complex. It should be well-named and well-formated.\n",
    "- __ / 1 point - Meets all coding guidelines / Idiomatic scikit-learn code.\n",
    "- __ / 2 points - Passed Level 1 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 2 test set performance. These point are all or none passed on tests.\n",
    "- __ / 2 points - Passed Level 3 test set performance. These point are all or none passed on tests.\n",
    "\n",
    "\n",
    "Hints\n",
    "------\n",
    "\n",
    "- Each person should attempt it individually. Then combine individual efforts in Deepnote.\n",
    "- Think about the best way to encode different types of features.\n",
    "- Perform EDA in a separate notebook. I suggest the `pandas_profiling` package\n",
    "    ```\n",
    "    from pandas_profiling import ProfileReport\n",
    "    profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "    profile.to_widgets()\n",
    "    profile.to_file(\"Pandas Profiling Report.html\")\n",
    "    ```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "color-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "tracked-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Do NOT import anything else\n",
    "from   category_encoders       import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   sklearn.compose         import *\n",
    "from   sklearn.experimental    import enable_iterative_imputer\n",
    "from   sklearn.impute          import *\n",
    "from   sklearn.linear_model    import LinearRegression \n",
    "from   sklearn.metrics         import mean_absolute_error # Easier to interpert than MSE. We'll discuss it in detail later\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.pipeline        import Pipeline\n",
    "from   sklearn.preprocessing   import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cubic-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "august-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your best model for the data\n",
    "# Friendly reminders: \n",
    "# - Use only imports given\n",
    "# - Create a pipeline instance called `pipe`\n",
    "# - Only use Linear Regression with default hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "computational-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect pipe object\n",
    "assert \"pipe\" in dir()\n",
    "assert type(pipe) == Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "accredited-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Level 1 test set performance ðŸ™‚\n",
      "Passed Level 2 test set performance ðŸ™‚\n",
      "Passed Level 3 test set performance ðŸ™‚\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final model on test set\n",
    "# This code is commented out because you do not have access to the test set\n",
    "\n",
    "# X_test = pd.read_csv(\"instructor/assignment_2_X_test.csv\", header=0)\n",
    "# y_test = pd.read_csv(\"instructor/assignment_2_y_test.csv\", header=0)\n",
    "# y_test = y_test.values.ravel()\n",
    "# y_pred = pipe.predict(X_test)\n",
    "# mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# assert mae_test <= 325\n",
    "# print(\"Passed Level 1 test set performance ðŸ™‚\")\n",
    "\n",
    "# assert mae_test <= 315\n",
    "# print(\"Passed Level 2 test set performance ðŸ™‚\")\n",
    "\n",
    "# assert mae_test <= 310\n",
    "# print(\"Passed Level 3 test set performance ðŸ™‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-agency",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
