{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imputing-Missing-Values\" data-toc-modified-id=\"Imputing-Missing-Values-1\">Imputing Missing Values</a></span></li><li><span><a href=\"#Let's-apply-the-feature-engineering-hierarchy-to-imputing-missing-values\" data-toc-modified-id=\"Let's-apply-the-feature-engineering-hierarchy-to-imputing-missing-values-2\">Let's apply the feature engineering hierarchy to imputing missing values</a></span></li><li><span><a href=\"#How-to-impute-missing-values:-Ad-hoc\" data-toc-modified-id=\"How-to-impute-missing-values:-Ad-hoc-3\">How to impute missing values: Ad hoc</a></span></li><li><span><a href=\"#How-to-impute-missing-values:-Hand-crafted-Rules\" data-toc-modified-id=\"How-to-impute-missing-values:-Hand-crafted-Rules-4\">How to impute missing values: Hand-crafted Rules</a></span></li><li><span><a href=\"#How-to-impute-missing-values:-Learned-Rules\" data-toc-modified-id=\"How-to-impute-missing-values:-Learned-Rules-5\">How to impute missing values: Learned Rules</a></span></li><li><span><a href=\"#What-is-fit_transform?\" data-toc-modified-id=\"What-is-fit_transform?-6\">What is fit_transform?</a></span></li><li><span><a href=\"#How-to-impute-missing-values:-Learned-Simple-Model\" data-toc-modified-id=\"How-to-impute-missing-values:-Learned-Simple-Model-7\">How to impute missing values: Learned Simple Model</a></span></li><li><span><a href=\"#KNN-Based-Missing-Value-Imputation\" data-toc-modified-id=\"KNN-Based-Missing-Value-Imputation-8\">KNN Based Missing Value Imputation</a></span></li><li><span><a href=\"#scikit-learn's-IterativeImputer\" data-toc-modified-id=\"scikit-learn's-IterativeImputer-9\">scikit-learn's IterativeImputer</a></span></li><li><span><a href=\"#Marking-imputed-values\" data-toc-modified-id=\"Marking-imputed-values-10\">Marking imputed values</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-11\">Check for understanding</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-12\">Takeaways</a></span></li><li><span><a href=\"#Sources-of-Inspiration\" data-toc-modified-id=\"Sources-of-Inspiration-13\">Sources of Inspiration</a></span></li><li><span><a href=\"#Bonus-Materials\" data-toc-modified-id=\"Bonus-Materials-14\">Bonus Materials</a></span></li><li><span><a href=\"#What-can-you-do-when-you-have-missing-values?\" data-toc-modified-id=\"What-can-you-do-when-you-have-missing-values?-15\">What can you do when you have missing values?</a></span></li><li><span><a href=\"#How-to-impute-missing-values:-Learned-Complex-Model\" data-toc-modified-id=\"How-to-impute-missing-values:-Learned-Complex-Model-16\">How to impute missing values: Learned Complex Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Imputing Missing Values</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Let's apply the feature engineering hierarchy to imputing missing values</h2></center>\n",
    "\n",
    "- Ad hoc\n",
    "- Hand-crafted rules\n",
    "- Feature learning:\n",
    "    - Rule-based models\n",
    "    - Simple models\n",
    "    - Complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to impute missing values: Ad hoc</h2></center>\n",
    "\n",
    "1. Visually inspect.\n",
    "1. Try to get the missing data!\n",
    "1. Given domain knowledge, guess value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to impute missing values: Hand-crafted Rules</h2></center>\n",
    "\n",
    "1. Replace with a reasonable guess based on knowledge of the underlying domain (heuristic).\n",
    "1. Replace with random value sampled from the empirical distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to impute missing values: Learned Rules</h2></center>\n",
    "\n",
    "Calculate the central tendency of existing values and impute them for missing data:\n",
    "\n",
    "- Median works best for numeric features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Mode works best for categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another option for categorical features - add \"missing\" as a new level for the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There only reason to impute the mean is because the median is too costly to compute. In this situations, you can easily compute the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's replace a single actual value with a missing value\n",
    "original_data_point = X_train[0][0]\n",
    "X_train[0][0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# help(SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create our imputer to replace missing values with the median\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "X_train_imp = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>What is fit_transform?</h2></center>\n",
    "\n",
    "`fit(X,  y=None)` Fit the model according to the given training data. This is often estimating parameters. In the case of SimpleImputer that finding the mean.\n",
    "\n",
    "`fit_transform(X, y=None, **fit_params)` Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.\n",
    "\n",
    "This is only for training data!\n",
    "\n",
    "Test data will just use `transform` method (the parameters come from the training dataset)\n",
    "\n",
    "<center><img src=\"../images/pipeline-diagram.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal datapoint:   5.1\n",
      "Imputated datapoint: 5.8\n"
     ]
    }
   ],
   "source": [
    "# Let's compare\n",
    "print(f\"Orginal datapoint: {original_data_point:>5}\")\n",
    "print(f\"Imputated datapoint: {X_train_imp[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply model to test dataset with transform method\n",
    "# The median of the feature in the training will be used to predict missing values in the test set\n",
    "X_test_imp = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to impute missing values: Learned Simple Model</h2></center>\n",
    "\n",
    "Fit a model that estimates a missing value based on other features.\n",
    "\n",
    "- [Linear Regression](https://en.wikipedia.org/wiki/Imputation_(statistics)#Regression) \n",
    "- [k-nearest neighbors algorithm (k-NN) ](http://conteudo.icmc.usp.br/pessoas/gbatista/files/his2002.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>KNN Based Missing Value Imputation</h2></center>\n",
    " \n",
    "Each missing value is imputed from the mean of n nearest neighbors, in the training set, so long as the features which neither sample are missing are near. \n",
    "\n",
    "Euclidean distance is the distance default metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X = [[1,      2, np.nan], \n",
    "     [3,      4, 3], \n",
    "     [np.nan, 6, 5], \n",
    "     [8,      8, 7]]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>scikit-learn's IterativeImputer</h2></center>\n",
    "\n",
    "Models each feature with missing values as a function of other features, and uses that estimate for imputation.\n",
    "\n",
    "An iterated round-robin fashion: \n",
    "\n",
    "- At each step, a feature column is designated as output y and the other feature columns are treated as inputs X. \n",
    "- A regressor is fit on (X, y) for known y. \n",
    "- Then, the regressor is used to predict the missing values of y. \n",
    "\n",
    "This is done for each feature in an iterative fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://scikit-learn.org/stable/modules/impute.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# help(IterativeImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imp = IterativeImputer()\n",
    "X_train_imp = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal datapoint:   5.1\n",
      "Imputated datapoint: 5.038868308952402\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orginal datapoint: {original_data_point:>5}\")\n",
    "print(f\"Imputated datapoint: {X_train_imp[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Marking imputed values</h2></center>\n",
    "\n",
    "The presence of missing data is a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "X = np.array([[-1, 42, -1, 1, 3]])\n",
    "\n",
    "indicator = MissingIndicator(missing_values=-1, features=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False, False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result is an indicator vector\n",
    "mask_all = indicator.fit_transform(X)\n",
    "mask_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://scikit-learn.org/stable/modules/impute.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "What should you do if you are missing target values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Discard that instance. One of the assumptions of Supervised Machine Learning is that each instance has a label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reframe the problem as a Reinforcement Learning or Unsupervised problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Feature Engineering (FE) creates derived data that improve model fitting, thus improving performance metrics.\n",
    "- All feature engineering, including imputation, be done through\n",
    "    - Ad hoc\n",
    "    - Learned rules\n",
    "    - Simple models\n",
    "    - Complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Sources of Inspiration</h2></center>\n",
    "\n",
    "- https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Bonus Materials</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>What can you do when you have missing values?</h2></center>\n",
    "\n",
    "You have 3 choices:\n",
    "\n",
    "1. Drop rows with missing values\n",
    "2. Impute missing values\n",
    "3. Choose a machine learning algorithm that is robust to missing value\n",
    "\n",
    "1. Dropping rows with missing values is the easiest and works well when there is a small proportion of missing value relative to complete values.\n",
    "\n",
    "2. Imputing missing values includes ad hoc choices, hand-crafted rules, and machine learning models.\n",
    "\n",
    "3. Most machine learning models do not handle missing values. One notable exception is [lightgbm](https://github.com/microsoft/LightGBM) which can handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/impute/_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[61.        , 22.        , 43.        , 27.74898065, 67.        ],\n",
       "       [50.92363569,  6.        , 27.        ,  8.        , 11.        ],\n",
       "       [83.        , 51.        , 28.62176532, 32.        ,  9.        ],\n",
       "       [74.        , 20.72107515, 35.        , 26.        , 97.        ],\n",
       "       [67.54222008,  4.        , 13.        , 45.        , 33.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example of IterativeImputer\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Create dataset with missing values\n",
    "data = [[61, 22, 43,np.nan,67],\n",
    "        [np.nan, 6, 27, 8, 11],\n",
    "        [83, 51, np.nan, 32, 9],\n",
    "        [74, np.nan, 35, 26, 97],\n",
    "        [np.nan, 4, 13,45, 33]]\n",
    "\n",
    "# Impute missing values using iterative imputer\n",
    "iter_imp = IterativeImputer(random_state= 42)\n",
    "iter_imp.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to impute missing values: Learned Complex Model</h2></center>\n",
    "\n",
    "<center><img src=\"../images/dl.png\" width=\"70%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Sources: \n",
    "\n",
    "- https://www.theanalysisfactor.com/seven-ways-to-make-up-data-common-methods-to-imputing-missing-data/\n",
    "- https://ssc.io/pdf/p2017-biessmann.pdf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
